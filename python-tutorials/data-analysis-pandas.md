# Python Data Analysis with Pandas

Pandas is the most popular library for data analysis in Python. This guide covers everything from basic data manipulation to advanced analysis techniques.

## Installation

```bash
pip install pandas numpy matplotlib
```

## Loading Data

```python
import pandas as pd

# From CSV
df = pd.read_csv('data.csv')

# From Excel
df = pd.read_excel('data.xlsx')

# From JSON
df = pd.read_json('data.json')

# From SQL
from sqlalchemy import create_engine
engine = create_engine('sqlite:///database.db')
df = pd.read_sql('SELECT * FROM table', engine)
```

## Basic Operations

```python
# View data
print(df.head())       # First 5 rows
print(df.tail())       # Last 5 rows
print(df.info())       # Column types and null values
print(df.describe())   # Statistical summary

# Select columns
print(df['column_name'])
print(df[['col1', 'col2']])

# Select rows
print(df[df['age'] > 30])  # Filter by condition
```

## Data Cleaning

```python
# Remove duplicates
df = df.drop_duplicates()

# Handle missing values
df = df.dropna()              # Remove rows with NaN
df.fillna(0, inplace=True)    # Fill with value
df.interpolate()              # Fill with interpolation

# Fix data types
df['age'] = df['age'].astype(int)
df['date'] = pd.to_datetime(df['date'])
```

## Grouping and Aggregation

```python
# Group by column and aggregate
grouped = df.groupby('category')['value'].mean()

# Multiple aggregations
df.groupby('category').agg({
    'value': ['mean', 'sum', 'count'],
    'category2': 'max'
})

# Pivot tables
pivot = df.pivot_table(
    values='sales',
    index='category',
    columns='region',
    aggfunc='sum'
)
```

## Merging DataFrames

```python
# Merge/join
merged = pd.merge(df1, df2, on='key', how='inner')

# Concatenate
combined = pd.concat([df1, df2], axis=0)

# Append (deprecated, use concat instead)
df = pd.concat([df, new_row], ignore_index=True)
```

## Data Visualization

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Bar chart
df['category'].value_counts().plot(kind='bar')
plt.title('Distribution')
plt.show()

# Histogram
df['value'].plot(kind='hist', bins=30)
plt.title('Distribution')
plt.show()

# Line chart
df.plot(x='date', y='value', kind='line')
plt.title('Time Series')
plt.show()

# Box plot
df.plot(kind='box')
plt.title('Distribution Summary')
plt.show()
```

## Time Series Analysis

```python
# Set datetime index
df = df.set_index('date')

# Resample by period
daily_avg = df.resample('D').mean()
monthly_avg = df.resample('M').mean()

# Rolling window
df['rolling_mean'] = df['value'].rolling(window=7).mean()

# Time difference
df['diff'] = df['value'].diff()
```

## Export Data

```python
# Save to CSV
df.to_csv('output.csv', index=False)

# Save to Excel
df.to_excel('output.xlsx', index=False)

# Save to JSON
df.to_json('output.json', indent=2)

# Save to SQL
df.to_sql('table_name', engine, if_exists='replace', index=False)
```

## Best Practices

1. **Always check data types** before operations
2. **Handle NaN values** explicitly
3. **Use vectorized operations** (faster than loops)
4. **Copy data** before modifying: `df_copy = df.copy()`
5. **Validate results** after transformations

---

*Generated by AI â€¢ Updated February 2026*